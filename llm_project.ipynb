{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import Annotated, List, Tuple, Union\n",
    "from langchain.chains import create_history_aware_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"#\"\n",
    "LANGCHAIN_API_KEY = \"#\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States:\n",
    "\n",
    "Class structure used to format code generation and pass error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict, List\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the graph.\n",
    "\n",
    "    Attributes:\n",
    "        error : Binary flag for control flow to indicate whether test error was tripped (\"yes\" or \"no\")\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries \n",
    "        code_result: Output of code solution once executed\n",
    "    \"\"\"\n",
    "\n",
    "    error : str\n",
    "    messages : List\n",
    "    generation : str\n",
    "    iterations : int\n",
    "    code_result: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"user_question\": \"What are the Ki values using DNA-directed DNA polymerase in humans?\",\n",
      "  \"EC_number\": \"2.7.7.7\",\n",
      "  \"organism\": \"Homo sapiens\",\n",
      "  \"additional_data\": \"Ki values\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY, model=\"gpt-4-0125-preview\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     '''You are an expert at parsing information from requests regarding the BRENDA enzyme database. Based on \\\n",
    "     the BRENDA SOAP API documentation, analyze the following request and try to extrapolate EC numbers, organism names, and other relevant \\\n",
    "     information for querying the BRENDA SOAP API based on the question being asked. \\\n",
    "     Return the result in a JSON format.  \\\n",
    "     If the user mentions an enzyme, use background knowledge of the BRENDA database to assign that an EC number.\\\n",
    "     Organism names should be rewritten as binomial nomenclature. \\\n",
    "     Make sure you specify the actual question being requested by the user in a field called \"user_question:\". \\\n",
    "     Add any other relevant information needed for the BRENDA API call by creating new fields as needed. \\\n",
    "     Replace a field with None if nothing can be extrapolated for that field. \\\n",
    "     \n",
    "     For example: if the user asks \"What are the ligands associated with inhibition in DNA-directed DNA polymerase in humans?\", \n",
    "     return:\n",
    "     {{\n",
    "        \"user_question\": \"What are the ligands associated with inhibition in DNA-directed DNA polymerase in humans?\",\n",
    "        \"EC_number\": \"2.7.7.7\",\n",
    "        \"organism\": \"Homo sapiens\",\n",
    "        \"ligand_properties:\" \"inhibition\"\n",
    "     }}\n",
    "     In this example, ligand_properties is an example of a new field created for this specific question to fill in relevant information for answering the question. \\\n",
    "     In this case, it is describing the type of ligands to search for, and will not appear in every question.\n",
    "\n",
    "     Another example: if the user asks \"What is the optimum pH for aldose reductase in mice?\", \n",
    "     return:\n",
    "     {{\n",
    "        \"user_question\": \"What is the optimum pH for aldose reductase in mice?\",\n",
    "        \"EC_number\": \"1.1.1.21\",\n",
    "        \"organism\": \"Mus musculus\",\n",
    "        \"additional_data:\" \"optimum pH values\"\n",
    "     }}\n",
    "    '''),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# output_parser transforms the output of the model just the string\n",
    "chain = prompt | llm | output_parser\n",
    "test1 = chain.invoke({\"input\":\"What are the Ki values using DNA-directed DNA polymerase in humans?\"})\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a docloader\n",
    "# Load, chunk and index the contents of the blog.\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader, UnstructuredHTMLLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# loads documentation from web\n",
    "loader = WebBaseLoader(\"https://www.brenda-enzymes.org/soap.php\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(openai_api_key = OPENAI_API_KEY))\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# PROMPT FOR THE CODE GENERATOR\n",
    "code_generator_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",'''You are a expert coding assistant who is proficient with the BRENDA SOAP API and Python 3. \n",
    "                                        \n",
    "    Write code to print data that can then answer the user's question.\n",
    "    Use only the following pieces of retrieved context from the BRENDA SOAP API documentation to answer the question. Do not retrieve data from any external sources to answer the question.\n",
    "    Context: {context}\n",
    "      \n",
    "    Feel free to make as many or as few API calls as needed to the BRENDA SOAP API to answer the question.\n",
    "    Make sure that any API calls are *ONLY* using the function names, syntax, and parameters *ACTUALLY DOCUMENTED* in the context BRENDA SOAP API documentation *VERBATIM*.\n",
    "    If the question requires more than one API call to answer it, write multiple API calls. Ensure any code you provide can be executed with all required imports and variables defined.\n",
    "    Structure your answer with a description of the code solution. Then list the imports. And finally list the functioning code block. \n",
    "    \n",
    "    Make sure to include all of the code in the needed to run any API calls necessary, including:\n",
    "        wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "        password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "        client = Client(wsdl)\n",
    "\n",
    "    The email for any BRENDA SOAP API calls made are \"siavash.raissi@tufts.edu\".\n",
    "    Do not print anything other than the code solution.\n",
    "    Make sure a print statement is included to print the answer to the user question in the terminal.\n",
    "    \n",
    "    Fill in *ALL* of the other parameters as needed according only to the BRENDA API documentation and examples.\n",
    "    The priority is that that *EVERY* parameter is included as specified by the BRENDA SOAP API documentation, and the 'ecNumber*' and 'organism*' fields are filled out.\n",
    "      \n",
    "    If an error occurs with \"Missing element\", go through the function syntax in the context BRENDA API documentation, and for each parameter, sure that **EVERY** parameter is included in the corresponding code.\n",
    "    Often, the parameter missing is NOT the one specified by the error.\n",
    "                       \n",
    "    For example, for the question: \"What is the Ki values for enzyme 1.1.1.1 in humans?\", the following code should be printed as according to the BRENDA SOAP API documentation:\n",
    "        from zeep import Client\n",
    "        import hashlib\n",
    "        wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "        password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "        client = Client(wsdl)\n",
    "        parameters = (\"siavash.raissi@tufts.edu\",password,\"ecNumber*1.1.1.1\", \"kiValue*\", \"kiValueMaximum*\", \"inhibitor*\", \"commentary*\", \"organism*Homo sapiens\", \"ligandStructureId*\", \"literature*\")\n",
    "        resultString = client.service.getKiValue(*parameters)\n",
    "        print(resultString)\n",
    "\n",
    "    Another example: for the user question: \"What has a higher range of IC50 values: enzyme 1.1.1.1 or enzyme 1.1.1.2?\", the following code should be printed as according to the BRENDA SOAP API documentation:\n",
    "        import hashlib\n",
    "        from zeep import Client\n",
    "        wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "        password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "        client = Client(wsdl)\n",
    "        # For enzyme 1.1.1.1\n",
    "        parameters_1 = (\"siavash.raissi@tufts.edu\", password, \"ecNumber*1.1.1.1\", \"ic50Value*\", \"ic50ValueMaximum*\", \"inhibitor*\", \"commentary*\", \"organism*\", \"ligandStructureId*\", \"literature*\")\n",
    "        resultString_1 = client.service.getIc50Value(*parameters_1)\n",
    "        # For enzyme 1.1.1.2\n",
    "        parameters_2 = (\"siavash.raissi@tufts.edu\", password, \"ecNumber*1.1.1.2\", \"ic50Value*\", \"ic50ValueMaximum*\", \"inhibitor*\", \"commentary*\", \"organism*\", \"ligandStructureId*\", \"literature*\")\n",
    "        resultString_2 = client.service.getIc50Value(*parameters_2)\n",
    "        print(resultString_1, resultString_2)\n",
    "      \n",
    "    Another example: if the user asks \"What inhibitors are known for the enzyme acetaldehyde dehydrogenase?\", the following code should be printed as according to the BRENDA SOAP API documentation:\n",
    "        import hashlib \n",
    "        wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "        password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "        client = Client(wsdl)\n",
    "        parameters = (\"siavash.raissi@tufts.edu\",password,\"ecNumber*1.2.1.10\", \"organism*\", \"inhibitor*\", \"commentary*\", \"ligandStructureId*\", \"literature*\")\n",
    "        resultString = client.service.getInhibitors(*parameters)\n",
    "        print(resultString)\n",
    "      \n",
    "    Another example: if the user asks: \"What are the subunits in the enzyme pyruvate kinase in humans?\", the following code should be printed as according to the BRENDA SOAP API documentation:\n",
    "        import hashlib \n",
    "        wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "        password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "        client = Client(wsdl)\n",
    "        parameters = (\"siavash.raissi@tufts.edu\",password,\"ecNumber*2.7.1.40\", \"subunits*\", \"organism*\", \"commentary*\", \"literature*\")\n",
    "        resultString = client.service.getSubunits(*parameters)\n",
    "        print(resultString)\n",
    "\n",
    "    Here is the user question:\"'''),\n",
    "    (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "\n",
    "# pydantic template for how to structure code - helps pinpoint errors\n",
    "class code(BaseModel):\n",
    "    \"\"\"Code output\"\"\"\n",
    "\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "    description = \"Schema for code solutions to questions using BRENDA.\"\n",
    "\n",
    "# formats context (retriever for BRENDA documentation) for easy parsing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "code_generator_llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0, openai_api_key = OPENAI_API_KEY)\n",
    "code_generator_chain = (\n",
    "    code_generator_prompt\n",
    "    | code_generator_llm.with_structured_output(code)\n",
    ")\n",
    "\n",
    "# test solution\n",
    "# solution = code_generator_chain.invoke({\"context\": retriever | format_docs, \"messages\":[(\"user\",\"What is the molecular weight of EC 1.1.1.2 in humans?\")]})\n",
    "# print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, FunctionMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreter Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TEST BRENDA API CALL\n",
    "# -------------------------------------------------------------\n",
    "# test, manually written BRENDA API call:\n",
    "# querying the molecular weight of aldose reductase\n",
    "#\n",
    "# from zeep import Client\n",
    "# import hashlib\n",
    "# wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "# password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "# client = Client(wsdl)\n",
    "# parameters = (\"siavash.raissi@tufts.edu\",password,\"ecNumber*1.1.1.21\", \"organism*Homo sapiens\", \n",
    "#               \"molecularWeight*\", \"molecularWeightMaximum*\", \"commentary*\", \"literature*\")\n",
    "# resultString = client.service.getMolecularWeight(*parameters)\n",
    "#\n",
    "# user_question = \"What is the molecular weight of aldose reductase?\"\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import functools\n",
    "\n",
    "interpreterprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''You are an expert at understanding and interpreting results from the BRENDA API. Use the data generated by BRENDA to answer the user's question \\\n",
    "     concisely.\n",
    "     \n",
    "     Here is the result of the BRENDA API call: {code_result}\n",
    "     \n",
    "     Here is the user question:'''),\n",
    "     (\"placeholder\", \"{question}\")\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# output_parser transforms the output of the model just the string\n",
    "interpreterchain = interpreterprompt | llm\n",
    "interpreternode = functools.partial(agent_node, agent=interpreterchain, name=\"interpret\")\n",
    "\n",
    "\n",
    "# test2 = chain.invoke({\"user_question\":user_question, \"resultString\":resultString})\n",
    "# test1 = chain.invoke({\"input\":\"What are the tissues using DNA-directed DNA polymerase in humans?\"})\n",
    "# print(resultString) \n",
    "# print(test2)\n",
    "# accurately reports a range of 32,000-39,000 da \n",
    "# should it be more precise, give a consensus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Executor Agent with Coder Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Max tries\n",
    "max_iterations = 5\n",
    "\n",
    "# Reflect\n",
    "# flag = 'reflect'\n",
    "flag = 'do not reflect'\n",
    " \n",
    "### Nodes\n",
    "\n",
    "# return to this function if the code has an error\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"GENERATING CODE SOLUTION\")\n",
    "    \n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    # generates again based off error BEFORE trying to generate the solution\n",
    "    if error == \"yes\":\n",
    "        messages += [(\"user\",\"Now, try again, specifically targeting the error that was generated. Invoke the code tool to structure the output with a prefix, imports, and code block:\")]\n",
    "        \n",
    "    # Solution\n",
    "    code_solution = code_generator_chain.invoke({\"context\": retriever | format_docs, \"messages\": messages})\n",
    "    messages += [(\"assistant\",f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\")]\n",
    "    \n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "# EXECUTOR AGENT\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"CHECKING CODE\")\n",
    "    \n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    # Get solution components\n",
    "    prefix = code_solution.prefix\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    # Check if the import specifically fails\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"CODE IMPORT CHECK: FAILED\")\n",
    "        error_message = [(\"user\", f'''Your solution failed the import test: {e}''')]\n",
    "        messages += error_message\n",
    "        return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations, \"error\": \"yes\"}\n",
    "    \n",
    "    # Checks the non-import code in addition to imports\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "    except Exception as e:\n",
    "        print(\"CODE BLOCK CHECK: FAILED\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
    "        # if \"Missing element\" in str(e):\n",
    "        #     error_message = [(\"user\", f'''Your solution failed the code execution test. You have a parameter missing in your function call. \n",
    "        #                       Make sure every parameter in the function call corresponds to exactly those in the BRENDA SOAP API documentation.\n",
    "        #                       For instance, if calling getKmValue, make sure that \"literature*\" and \"kmValueMaximum*\" is included in the parameters.''')]\n",
    "        messages += error_message\n",
    "        return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations, \"error\": \"yes\"}\n",
    "  \n",
    "    # returns if no errors present\n",
    "    print(\"NO CODE TEST FAILURES\")\n",
    "    \n",
    "    # saves the errorless output of the code to code_result and returns\n",
    "    print(\"SAVING RESULT\")\n",
    "    stdout = io.StringIO()\n",
    "    with redirect_stdout(stdout):\n",
    "        exec(imports + \"\\n\" + code)\n",
    "    code_result = stdout.getvalue()\n",
    "\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations, \"error\": \"no\", \"code_result\": code_result}\n",
    "\n",
    "# optional node used to reflect on error\n",
    "def reflect(state: GraphState):\n",
    "    \"\"\"\n",
    "    Reflect on errors\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"GENERATING CODE SOLUTION\")\n",
    "    \n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "\n",
    "    # Prompt reflection\n",
    "    reflection_message = [(\"user\", \"\"\"You tried to solve this problem and failed a unit test. Reflect on this failure\n",
    "                                    given the provided documentation. Write a few key suggestions based on the \n",
    "                                    documentation to avoid making this mistake again.\"\"\")]\n",
    "    \n",
    "    # Add reflection\n",
    "    reflections = code_generator_chain.invoke({\"context\": retriever | format_docs, \"messages\": messages})\n",
    "    messages += [(\"assistant\" , f\"Here are reflections on the error: {reflections}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "# conditional edge for deciding when to finish\n",
    "def decide_to_interpret(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"FINISH\")\n",
    "        return \"interpret\"\n",
    "    else:\n",
    "        print(\"RETRY SOLUTION\")\n",
    "        if flag == 'reflect':\n",
    "            return \"reflect\"\n",
    "        else:\n",
    "            return \"generate\"\n",
    "        \n",
    "def interpret(state: GraphState):\n",
    "    \"\"\"\n",
    "    Interpret the code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, messages\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"INTERPRETING CODE SOLUTION\")\n",
    "    \n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    code_result = state[\"code_result\"]\n",
    "\n",
    "    if iterations == max_iterations and state[\"error\"] == \"yes\":\n",
    "        print(f\"ERROR: solution could not be generated with max iterations: {max_iterations}\")\n",
    "    else:\n",
    "        interpretation = interpreterchain.invoke({\"code_result\": code_result, \"question\": [messages[0]]})\n",
    "        print(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, FunctionMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreter Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TEST BRENDA API CALL\n",
    "# -------------------------------------------------------------\n",
    "# test, manually written BRENDA API call:\n",
    "# querying the molecular weight of aldose reductase\n",
    "#\n",
    "# from zeep import Client\n",
    "# import hashlib\n",
    "# wsdl = \"https://www.brenda-enzymes.org/soap/brenda_zeep.wsdl\"\n",
    "# password = hashlib.sha256(\"PASSWORD\".encode(\"utf-8\")).hexdigest()\n",
    "# client = Client(wsdl)\n",
    "# parameters = (\"siavash.raissi@tufts.edu\",password,\"ecNumber*1.1.1.21\", \"organism*Homo sapiens\", \n",
    "#               \"molecularWeight*\", \"molecularWeightMaximum*\", \"commentary*\", \"literature*\")\n",
    "# resultString = client.service.getMolecularWeight(*parameters)\n",
    "#\n",
    "# user_question = \"What is the molecular weight of aldose reductase?\"\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import functools\n",
    "\n",
    "interpreterprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''You are an expert at understanding and interpreting results from the BRENDA API. Use the data generated by BRENDA to answer the user's question \\\n",
    "     concisely. Provide only the information being requested by the user.\n",
    "     \n",
    "     Here is the result of the BRENDA API call: {code_result}\n",
    "     \n",
    "     Here is the user question:\n",
    "     ''')\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# output_parser transforms the output of the model just the string\n",
    "interpreterchain = interpreterprompt | llm | output_parser\n",
    "interpreternode = functools.partial(agent_node, agent=interpreterchain, name=\"interpreter\")\n",
    "\n",
    "\n",
    "# test2 = chain.invoke({\"user_question\":user_question, \"resultString\":resultString})\n",
    "# test1 = chain.invoke({\"input\":\"What are the tissues using DNA-directed DNA polymerase in humans?\"})\n",
    "# print(resultString) \n",
    "# print(test2)\n",
    "# accurately reports a range of 32,000-39,000 da \n",
    "# should it be more precise, give a consensus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting Graph Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# stategraphs let nodes write to a shared state \n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"check_code\", code_check)  # executor agent\n",
    "workflow.add_node(\"reflect\", reflect)  # reflect\n",
    "workflow.add_node(\"interpret\", interpret)  # interpret result\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "# checks if decide_to_interpret results in an end, reflect, or generate and matches edges respectively\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_interpret,\n",
    "    {\n",
    "        \"interpret\": \"interpret\",\n",
    "        \"reflect\": \"reflect\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"reflect\", \"generate\")\n",
    "workflow.add_edge(\"interpret\", END)\n",
    "\n",
    "\n",
    "app = workflow.compile()\n",
    "question = \"What is the pH stability of 5’-3’ DNA Helicase, EC number 5.6.2.3?\"\n",
    "app.invoke({\"messages\":[(\"user\",question)],\"iterations\":0})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs166",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
